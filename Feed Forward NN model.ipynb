{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path on my system to training data\n",
    "train_path = \"./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_04835861-01-2013-10-16-13-19-35.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_17744725-01-2009-02-24-16-26-44.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_20983985-01-2013-05-16-16-16-00.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_23112025-01-2013-05-21-06-21-54.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_36551836-01-2013-05-21-17-39-57.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_38243026-05-2009-04-29-08-53-16.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_42990421-03a-2011-03-23-16-50-02.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_47451392-01-2014-01-22-22-42-34.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_63414187-01-2013-05-30-22-48-27.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_67458491-01-2013-11-07-12-36-22.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_74827807-04-2009-02-09-22-39-54.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_79761947-03-2012-06-24-02-09-34.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_91943076-01-2009-02-26-12-42-02.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_91943076-02-2009-02-26-22-15-13.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_96201346-01-2011-05-18-18-57-16.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Train/F_96201346-05-2011-06-03-22-36-07.csv\n"
     ]
    }
   ],
   "source": [
    "#Read all training data files\n",
    "from os import walk\n",
    "\n",
    "data_for_fall=[]\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(train_path):\n",
    "    \n",
    "    for file in filenames:\n",
    "        print(dirpath+file)\n",
    "        data = pd.read_csv(dirpath+file)\n",
    "        data.columns = ['Time','Rel_Time','Acc_X','Acc_Y','Acc_Z','Mg_X','Mg_Y','Mg_Z','Ang_X','Ang_Y','Ang_Z','Fall_indicator']\n",
    "        data_for_fall.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Rel_Time</th>\n",
       "      <th>Acc_X</th>\n",
       "      <th>Acc_Y</th>\n",
       "      <th>Acc_Z</th>\n",
       "      <th>Mg_X</th>\n",
       "      <th>Mg_Y</th>\n",
       "      <th>Mg_Z</th>\n",
       "      <th>Ang_X</th>\n",
       "      <th>Ang_Y</th>\n",
       "      <th>Ang_Z</th>\n",
       "      <th>Fall_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184020.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>2.0243</td>\n",
       "      <td>-8.4086</td>\n",
       "      <td>-2.95860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184020.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>2.0243</td>\n",
       "      <td>-8.4086</td>\n",
       "      <td>-2.95860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184020.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>2.0243</td>\n",
       "      <td>-8.4086</td>\n",
       "      <td>-2.95860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>184020.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>2.0243</td>\n",
       "      <td>-8.4086</td>\n",
       "      <td>-2.95860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184020.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>2.0243</td>\n",
       "      <td>-8.4086</td>\n",
       "      <td>-2.95860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>185220.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>8.7200</td>\n",
       "      <td>-1.8686</td>\n",
       "      <td>0.31143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>185220.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>8.7200</td>\n",
       "      <td>-1.8686</td>\n",
       "      <td>0.31143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>185220.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>8.7200</td>\n",
       "      <td>-1.8686</td>\n",
       "      <td>0.31143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>185220.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>8.7200</td>\n",
       "      <td>-1.8686</td>\n",
       "      <td>0.31143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>185220.0</td>\n",
       "      <td>735520.0</td>\n",
       "      <td>8.7200</td>\n",
       "      <td>-1.8686</td>\n",
       "      <td>0.31143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time  Rel_Time   Acc_X   Acc_Y    Acc_Z  Mg_X  Mg_Y  Mg_Z  Ang_X  \\\n",
       "0      184020.0  735520.0  2.0243 -8.4086 -2.95860     0     0     0      0   \n",
       "1      184020.0  735520.0  2.0243 -8.4086 -2.95860     0     0     0      0   \n",
       "2      184020.0  735520.0  2.0243 -8.4086 -2.95860     0     0     0      0   \n",
       "3      184020.0  735520.0  2.0243 -8.4086 -2.95860     0     0     0      0   \n",
       "4      184020.0  735520.0  2.0243 -8.4086 -2.95860     0     0     0      0   \n",
       "...         ...       ...     ...     ...      ...   ...   ...   ...    ...   \n",
       "23995  185220.0  735520.0  8.7200 -1.8686  0.31143     0     0     0      0   \n",
       "23996  185220.0  735520.0  8.7200 -1.8686  0.31143     0     0     0      0   \n",
       "23997  185220.0  735520.0  8.7200 -1.8686  0.31143     0     0     0      0   \n",
       "23998  185220.0  735520.0  8.7200 -1.8686  0.31143     0     0     0      0   \n",
       "23999  185220.0  735520.0  8.7200 -1.8686  0.31143     0     0     0      0   \n",
       "\n",
       "       Ang_Y  Ang_Z  Fall_indicator  \n",
       "0          0      0               0  \n",
       "1          0      0               0  \n",
       "2          0      0               0  \n",
       "3          0      0               0  \n",
       "4          0      0               0  \n",
       "...      ...    ...             ...  \n",
       "23995      0      0               0  \n",
       "23996      0      0               0  \n",
       "23997      0      0               0  \n",
       "23998      0      0               0  \n",
       "23999      0      0               0  \n",
       "\n",
       "[24000 rows x 12 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print one file data in training\n",
    "data_for_fall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "#Creates windows of size=20 and steps forward by 1\n",
    "def create_dataset(X, Y, feature_size=20, step_size=1):\n",
    "    window_X, window_Y = [], []\n",
    "    for i in range(0, len(X) - feature_size, step_size):\n",
    "        #Feature size=20 (size of window)\n",
    "        window_data = X.iloc[i:(i + feature_size),:]\n",
    "        #Get all the 20 labels\n",
    "        labels = Y.iloc[i: i + feature_size]\n",
    "        #Append for each 20 sized windows, each stepped forward by 1\n",
    "        window_X.append(window_data)\n",
    "        #Get the max value- If window contains the row that has fall data then window labelled as fall\n",
    "        #The fall indicator can be any value >0 dependng on severity of fall\n",
    "        window_Y.append(labels.max())\n",
    "    return (window_X), np.array(window_Y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_features(data):\n",
    "    #Flattens the window data into one row\n",
    "    #Will get 20 rows of 3 columns each = 60 data points in each row\n",
    "    feature_columns = ['Acc_X','Acc_Y','Acc_Z']\n",
    "    sensor_values = data[feature_columns].values \n",
    "    features = sensor_values.flatten()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "#Get the training window data without overlap from other files\n",
    "train_X_window = []\n",
    "train_Y_window = []\n",
    "#For each file in the 16 training files\n",
    "for dataset in data_for_fall:\n",
    "    #Get the fall event location in the file (only one file at a time)\n",
    "    fall_event_loc = dataset[dataset['Fall_indicator']>0].index\n",
    "    #Get 2 seconds of data around fall event\n",
    "    for fall_loc in fall_event_loc:\n",
    "        data_index_lists = []\n",
    "        #2s of data - 1.5sec before fall, 0.5sec after fall\n",
    "        data_index_lists.append(list(range(fall_loc-30,fall_loc+25)))\n",
    "        #Get all the indices as a list    \n",
    "        drop_arr = list(chain.from_iterable(data_index_lists))\n",
    "        #Take only those indices that correspond to 2 seconds of data around fall event\n",
    "        dataset_sample = dataset.iloc[drop_arr]\n",
    "    \n",
    "\n",
    "        #Create windowed data for the file\n",
    "        train_each_X, train_each_Y = create_dataset(\n",
    "            dataset_sample[['Acc_X', 'Acc_Y', 'Acc_Z']],\n",
    "            dataset_sample[['Fall_indicator']],\n",
    "            feature_size=20\n",
    "        )\n",
    "    \n",
    "    \n",
    "        #Adding only non-fall data from the files\n",
    "        data_index_lists_non_fall=[]\n",
    "        \n",
    "        #1.2s of data - 10 seconds before fall, duration is 1.2 seconds\n",
    "        data_index_lists_non_fall.append(list(range(fall_loc-600,fall_loc-570)))\n",
    "        #Get all the indices as a list    \n",
    "        non_fall_indices = list(chain.from_iterable(data_index_lists_non_fall))\n",
    "        #Take only those indices that correspond to 2 seconds of data around fall event\n",
    "        dataset_sample_non_fall = dataset.iloc[non_fall_indices]\n",
    "\n",
    "\n",
    "        #Create windowed data for the file\n",
    "        train_each_X_non_fall, train_each_Y_non_fall = create_dataset(\n",
    "            dataset_sample_non_fall[['Acc_X', 'Acc_Y', 'Acc_Z']],\n",
    "            dataset_sample_non_fall[['Fall_indicator']],\n",
    "            feature_size=20\n",
    "        )\n",
    "\n",
    "\n",
    "        #Flatten the windowed data to get 60 features in a row\n",
    "        train_each_X_non_fall_flat = np.stack([to_features(d) for d in train_each_X_non_fall])  \n",
    "\n",
    "        #Flatten the windowed data to get 60 features in a row\n",
    "        train_each_X_flat = np.stack([to_features(d) for d in train_each_X])\n",
    "        #Append the data of each file\n",
    "        train_X_window.append(train_each_X_flat)\n",
    "        train_X_window.append(train_each_X_non_fall_flat)\n",
    "        train_Y_window.append(train_each_Y)\n",
    "        train_Y_window.append(train_each_Y_non_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n",
      "35\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for each_window in train_Y_window:\n",
    "    print(len(each_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_window[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_window[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4014 ,  0.62286, 10.589  , -1.8686 ,  0.77857,  8.5643 ,\n",
       "        -1.8686 ,  0.62286,  7.7857 , -1.5571 ,  1.2457 ,  7.1629 ,\n",
       "        -0.77857,  1.2457 ,  7.3186 ,  1.8686 ,  1.2457 ,  7.7857 ,\n",
       "         7.7857 , -1.09   ,  8.5643 ,  2.6471 ,  0.46714,  7.3186 ,\n",
       "        -0.62286, -3.7371 , 14.481  , -1.5571 ,  7.3186 , 11.056  ,\n",
       "        -2.0243 , -6.2286 , 10.433  , -3.27   , -1.5571 ,  9.81   ,\n",
       "        -1.7129 ,  0.     ,  9.81   , -0.77857,  0.15571,  9.4986 ,\n",
       "         0.15571, -0.93429,  9.4986 , -0.77857, -1.2457 ,  9.6543 ,\n",
       "        -0.77857, -1.2457 ,  9.4986 , -0.77857, -0.77857,  9.6543 ,\n",
       "        -0.46714, -0.15571,  9.81   , -1.8686 , -2.4914 ,  9.4986 ],\n",
       "       [-1.8686 ,  0.77857,  8.5643 , -1.8686 ,  0.62286,  7.7857 ,\n",
       "        -1.5571 ,  1.2457 ,  7.1629 , -0.77857,  1.2457 ,  7.3186 ,\n",
       "         1.8686 ,  1.2457 ,  7.7857 ,  7.7857 , -1.09   ,  8.5643 ,\n",
       "         2.6471 ,  0.46714,  7.3186 , -0.62286, -3.7371 , 14.481  ,\n",
       "        -1.5571 ,  7.3186 , 11.056  , -2.0243 , -6.2286 , 10.433  ,\n",
       "        -3.27   , -1.5571 ,  9.81   , -1.7129 ,  0.     ,  9.81   ,\n",
       "        -0.77857,  0.15571,  9.4986 ,  0.15571, -0.93429,  9.4986 ,\n",
       "        -0.77857, -1.2457 ,  9.6543 , -0.77857, -1.2457 ,  9.4986 ,\n",
       "        -0.77857, -0.77857,  9.6543 , -0.46714, -0.15571,  9.81   ,\n",
       "        -1.8686 , -2.4914 ,  9.4986 , -3.27   , -0.15571, 10.9    ],\n",
       "       [-1.8686 ,  0.62286,  7.7857 , -1.5571 ,  1.2457 ,  7.1629 ,\n",
       "        -0.77857,  1.2457 ,  7.3186 ,  1.8686 ,  1.2457 ,  7.7857 ,\n",
       "         7.7857 , -1.09   ,  8.5643 ,  2.6471 ,  0.46714,  7.3186 ,\n",
       "        -0.62286, -3.7371 , 14.481  , -1.5571 ,  7.3186 , 11.056  ,\n",
       "        -2.0243 , -6.2286 , 10.433  , -3.27   , -1.5571 ,  9.81   ,\n",
       "        -1.7129 ,  0.     ,  9.81   , -0.77857,  0.15571,  9.4986 ,\n",
       "         0.15571, -0.93429,  9.4986 , -0.77857, -1.2457 ,  9.6543 ,\n",
       "        -0.77857, -1.2457 ,  9.4986 , -0.77857, -0.77857,  9.6543 ,\n",
       "        -0.46714, -0.15571,  9.81   , -1.8686 , -2.4914 ,  9.4986 ,\n",
       "        -3.27   , -0.15571, 10.9    , -0.62286,  0.93429, 10.433  ],\n",
       "       [-1.5571 ,  1.2457 ,  7.1629 , -0.77857,  1.2457 ,  7.3186 ,\n",
       "         1.8686 ,  1.2457 ,  7.7857 ,  7.7857 , -1.09   ,  8.5643 ,\n",
       "         2.6471 ,  0.46714,  7.3186 , -0.62286, -3.7371 , 14.481  ,\n",
       "        -1.5571 ,  7.3186 , 11.056  , -2.0243 , -6.2286 , 10.433  ,\n",
       "        -3.27   , -1.5571 ,  9.81   , -1.7129 ,  0.     ,  9.81   ,\n",
       "        -0.77857,  0.15571,  9.4986 ,  0.15571, -0.93429,  9.4986 ,\n",
       "        -0.77857, -1.2457 ,  9.6543 , -0.77857, -1.2457 ,  9.4986 ,\n",
       "        -0.77857, -0.77857,  9.6543 , -0.46714, -0.15571,  9.81   ,\n",
       "        -1.8686 , -2.4914 ,  9.4986 , -3.27   , -0.15571, 10.9    ,\n",
       "        -0.62286,  0.93429, 10.433  , -0.77857, -0.93429, 10.277  ],\n",
       "       [-0.77857,  1.2457 ,  7.3186 ,  1.8686 ,  1.2457 ,  7.7857 ,\n",
       "         7.7857 , -1.09   ,  8.5643 ,  2.6471 ,  0.46714,  7.3186 ,\n",
       "        -0.62286, -3.7371 , 14.481  , -1.5571 ,  7.3186 , 11.056  ,\n",
       "        -2.0243 , -6.2286 , 10.433  , -3.27   , -1.5571 ,  9.81   ,\n",
       "        -1.7129 ,  0.     ,  9.81   , -0.77857,  0.15571,  9.4986 ,\n",
       "         0.15571, -0.93429,  9.4986 , -0.77857, -1.2457 ,  9.6543 ,\n",
       "        -0.77857, -1.2457 ,  9.4986 , -0.77857, -0.77857,  9.6543 ,\n",
       "        -0.46714, -0.15571,  9.81   , -1.8686 , -2.4914 ,  9.4986 ,\n",
       "        -3.27   , -0.15571, 10.9    , -0.62286,  0.93429, 10.433  ,\n",
       "        -0.77857, -0.93429, 10.277  , -0.31143,  0.77857, 11.834  ],\n",
       "       [ 1.8686 ,  1.2457 ,  7.7857 ,  7.7857 , -1.09   ,  8.5643 ,\n",
       "         2.6471 ,  0.46714,  7.3186 , -0.62286, -3.7371 , 14.481  ,\n",
       "        -1.5571 ,  7.3186 , 11.056  , -2.0243 , -6.2286 , 10.433  ,\n",
       "        -3.27   , -1.5571 ,  9.81   , -1.7129 ,  0.     ,  9.81   ,\n",
       "        -0.77857,  0.15571,  9.4986 ,  0.15571, -0.93429,  9.4986 ,\n",
       "        -0.77857, -1.2457 ,  9.6543 , -0.77857, -1.2457 ,  9.4986 ,\n",
       "        -0.77857, -0.77857,  9.6543 , -0.46714, -0.15571,  9.81   ,\n",
       "        -1.8686 , -2.4914 ,  9.4986 , -3.27   , -0.15571, 10.9    ,\n",
       "        -0.62286,  0.93429, 10.433  , -0.77857, -0.93429, 10.277  ,\n",
       "        -0.31143,  0.77857, 11.834  ,  0.62286,  1.5571 , 10.277  ],\n",
       "       [ 7.7857 , -1.09   ,  8.5643 ,  2.6471 ,  0.46714,  7.3186 ,\n",
       "        -0.62286, -3.7371 , 14.481  , -1.5571 ,  7.3186 , 11.056  ,\n",
       "        -2.0243 , -6.2286 , 10.433  , -3.27   , -1.5571 ,  9.81   ,\n",
       "        -1.7129 ,  0.     ,  9.81   , -0.77857,  0.15571,  9.4986 ,\n",
       "         0.15571, -0.93429,  9.4986 , -0.77857, -1.2457 ,  9.6543 ,\n",
       "        -0.77857, -1.2457 ,  9.4986 , -0.77857, -0.77857,  9.6543 ,\n",
       "        -0.46714, -0.15571,  9.81   , -1.8686 , -2.4914 ,  9.4986 ,\n",
       "        -3.27   , -0.15571, 10.9    , -0.62286,  0.93429, 10.433  ,\n",
       "        -0.77857, -0.93429, 10.277  , -0.31143,  0.77857, 11.834  ,\n",
       "         0.62286,  1.5571 , 10.277  , -2.18   ,  2.18   , 11.056  ],\n",
       "       [ 2.6471 ,  0.46714,  7.3186 , -0.62286, -3.7371 , 14.481  ,\n",
       "        -1.5571 ,  7.3186 , 11.056  , -2.0243 , -6.2286 , 10.433  ,\n",
       "        -3.27   , -1.5571 ,  9.81   , -1.7129 ,  0.     ,  9.81   ,\n",
       "        -0.77857,  0.15571,  9.4986 ,  0.15571, -0.93429,  9.4986 ,\n",
       "        -0.77857, -1.2457 ,  9.6543 , -0.77857, -1.2457 ,  9.4986 ,\n",
       "        -0.77857, -0.77857,  9.6543 , -0.46714, -0.15571,  9.81   ,\n",
       "        -1.8686 , -2.4914 ,  9.4986 , -3.27   , -0.15571, 10.9    ,\n",
       "        -0.62286,  0.93429, 10.433  , -0.77857, -0.93429, 10.277  ,\n",
       "        -0.31143,  0.77857, 11.834  ,  0.62286,  1.5571 , 10.277  ,\n",
       "        -2.18   ,  2.18   , 11.056  , -2.9586 ,  0.46714, 11.523  ],\n",
       "       [-0.62286, -3.7371 , 14.481  , -1.5571 ,  7.3186 , 11.056  ,\n",
       "        -2.0243 , -6.2286 , 10.433  , -3.27   , -1.5571 ,  9.81   ,\n",
       "        -1.7129 ,  0.     ,  9.81   , -0.77857,  0.15571,  9.4986 ,\n",
       "         0.15571, -0.93429,  9.4986 , -0.77857, -1.2457 ,  9.6543 ,\n",
       "        -0.77857, -1.2457 ,  9.4986 , -0.77857, -0.77857,  9.6543 ,\n",
       "        -0.46714, -0.15571,  9.81   , -1.8686 , -2.4914 ,  9.4986 ,\n",
       "        -3.27   , -0.15571, 10.9    , -0.62286,  0.93429, 10.433  ,\n",
       "        -0.77857, -0.93429, 10.277  , -0.31143,  0.77857, 11.834  ,\n",
       "         0.62286,  1.5571 , 10.277  , -2.18   ,  2.18   , 11.056  ,\n",
       "        -2.9586 ,  0.46714, 11.523  , -1.5571 , -0.46714, 11.367  ],\n",
       "       [-1.5571 ,  7.3186 , 11.056  , -2.0243 , -6.2286 , 10.433  ,\n",
       "        -3.27   , -1.5571 ,  9.81   , -1.7129 ,  0.     ,  9.81   ,\n",
       "        -0.77857,  0.15571,  9.4986 ,  0.15571, -0.93429,  9.4986 ,\n",
       "        -0.77857, -1.2457 ,  9.6543 , -0.77857, -1.2457 ,  9.4986 ,\n",
       "        -0.77857, -0.77857,  9.6543 , -0.46714, -0.15571,  9.81   ,\n",
       "        -1.8686 , -2.4914 ,  9.4986 , -3.27   , -0.15571, 10.9    ,\n",
       "        -0.62286,  0.93429, 10.433  , -0.77857, -0.93429, 10.277  ,\n",
       "        -0.31143,  0.77857, 11.834  ,  0.62286,  1.5571 , 10.277  ,\n",
       "        -2.18   ,  2.18   , 11.056  , -2.9586 ,  0.46714, 11.523  ,\n",
       "        -1.5571 , -0.46714, 11.367  , -1.8686 ,  0.31143,  9.0314 ]])"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_window[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.1143 ,   2.3357 ,   3.4257 , ...,  -8.2529 ,   7.3186 ,\n",
       "         13.236  ],\n",
       "       [ -1.5571 ,  -3.1143 ,   7.9414 , ...,  -2.0243 , -11.211  ,\n",
       "         19.62   ],\n",
       "       [  1.5571 ,   0.46714,  19.62   , ...,  -9.81   ,  -1.7129 ,\n",
       "          5.9171 ],\n",
       "       ...,\n",
       "       [ -1.6167 ,  -1.1119 ,  10.218  , ...,  -1.0158 ,   0.54891,\n",
       "          9.7729 ],\n",
       "       [ -1.5595 ,  -1.14   ,  10.246  , ...,  -1.0158 ,   0.46446,\n",
       "          9.8841 ],\n",
       "       [ -1.5309 ,  -1.1682 ,  10.329  , ...,  -0.90136,   0.43631,\n",
       "         10.051  ]])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate the windowed and flattened data of each file to form the training data\n",
    "train_X = np.concatenate(train_X_window,axis = 0)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 60)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [4],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenate the fall indicator of each file to form the training labels\n",
    "train_Y = np.concatenate(train_Y_window, axis=0)\n",
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 1)"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argwhere(train_Y > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all labels of fall_indicator > 1 to 1\n",
    "train_Y[train_Y > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argwhere(train_Y == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argwhere(train_Y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 1,497\n",
      "Trainable params: 1,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Basic MLP\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim=60))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 - 0s - loss: 1.0758 - accuracy: 0.6294 - val_loss: 1.2729 - val_accuracy: 0.7273\n",
      "Epoch 2/100\n",
      "22/22 - 0s - loss: 0.7232 - accuracy: 0.7166 - val_loss: 0.9725 - val_accuracy: 0.8052\n",
      "Epoch 3/100\n",
      "22/22 - 0s - loss: 0.5794 - accuracy: 0.7660 - val_loss: 0.8514 - val_accuracy: 0.7792\n",
      "Epoch 4/100\n",
      "22/22 - 0s - loss: 0.5048 - accuracy: 0.7820 - val_loss: 0.8001 - val_accuracy: 0.7662\n",
      "Epoch 5/100\n",
      "22/22 - 0s - loss: 0.4490 - accuracy: 0.8009 - val_loss: 0.7147 - val_accuracy: 0.7792\n",
      "Epoch 6/100\n",
      "22/22 - 0s - loss: 0.4057 - accuracy: 0.8183 - val_loss: 0.6672 - val_accuracy: 0.7792\n",
      "Epoch 7/100\n",
      "22/22 - 0s - loss: 0.3734 - accuracy: 0.8387 - val_loss: 0.6163 - val_accuracy: 0.8182\n",
      "Epoch 8/100\n",
      "22/22 - 0s - loss: 0.3475 - accuracy: 0.8532 - val_loss: 0.5957 - val_accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "22/22 - 0s - loss: 0.3229 - accuracy: 0.8648 - val_loss: 0.5617 - val_accuracy: 0.8442\n",
      "Epoch 10/100\n",
      "22/22 - 0s - loss: 0.3045 - accuracy: 0.8794 - val_loss: 0.5492 - val_accuracy: 0.8442\n",
      "Epoch 11/100\n",
      "22/22 - 0s - loss: 0.2823 - accuracy: 0.8983 - val_loss: 0.5323 - val_accuracy: 0.8442\n",
      "Epoch 12/100\n",
      "22/22 - 0s - loss: 0.2658 - accuracy: 0.9012 - val_loss: 0.5302 - val_accuracy: 0.8442\n",
      "Epoch 13/100\n",
      "22/22 - 0s - loss: 0.2463 - accuracy: 0.9055 - val_loss: 0.5201 - val_accuracy: 0.8442\n",
      "Epoch 14/100\n",
      "22/22 - 0s - loss: 0.2328 - accuracy: 0.9142 - val_loss: 0.5121 - val_accuracy: 0.8442\n",
      "Epoch 15/100\n",
      "22/22 - 0s - loss: 0.2170 - accuracy: 0.9201 - val_loss: 0.5368 - val_accuracy: 0.8312\n",
      "Epoch 16/100\n",
      "22/22 - 0s - loss: 0.2040 - accuracy: 0.9259 - val_loss: 0.5496 - val_accuracy: 0.8442\n",
      "Epoch 17/100\n",
      "22/22 - 0s - loss: 0.1905 - accuracy: 0.9302 - val_loss: 0.5667 - val_accuracy: 0.8442\n",
      "Epoch 18/100\n",
      "22/22 - 0s - loss: 0.1777 - accuracy: 0.9360 - val_loss: 0.5597 - val_accuracy: 0.8442\n",
      "Epoch 19/100\n",
      "22/22 - 0s - loss: 0.1677 - accuracy: 0.9462 - val_loss: 0.5785 - val_accuracy: 0.8442\n",
      "Epoch 20/100\n",
      "22/22 - 0s - loss: 0.1566 - accuracy: 0.9506 - val_loss: 0.5784 - val_accuracy: 0.8442\n",
      "Epoch 21/100\n",
      "22/22 - 0s - loss: 0.1472 - accuracy: 0.9622 - val_loss: 0.5829 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "22/22 - 0s - loss: 0.1362 - accuracy: 0.9680 - val_loss: 0.6034 - val_accuracy: 0.8571\n",
      "Epoch 23/100\n",
      "22/22 - 0s - loss: 0.1273 - accuracy: 0.9724 - val_loss: 0.6280 - val_accuracy: 0.8701\n",
      "Epoch 24/100\n",
      "22/22 - 0s - loss: 0.1189 - accuracy: 0.9709 - val_loss: 0.6154 - val_accuracy: 0.8571\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "history = model.fit(train_X, to_categorical(train_Y), epochs=100, batch_size=32, verbose=2, validation_split=0.1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/F_42990421-01-2011-02-19-15-59-57.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/F_42990421-02-2011-02-19-22-58-03.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/F_72858619-01-2008-06-26-07-27-49.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/F_72858619-02-2008-06-26-11-29-16.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/F_74827807-07-2009-02-16-19-10-44.csv\n",
      "./../Datasets/Fall examples/Fall examples/Farseeing/Data/Test/F_96201346-03-2011-05-21-06-19-42.csv\n"
     ]
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "# columns = ['Time','Acc_X','Acc_Y','Acc_Z','Fall_indicator']\n",
    "# train_data = pd.DataFrame() #columns=columns)\n",
    "data_for_fall_test=[]\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(test_path):\n",
    "    \n",
    "    for file in filenames:\n",
    "        print(dirpath+file)\n",
    "        data = pd.read_csv(dirpath+file)\n",
    "        data.columns = ['Time','Rel_Time','Acc_X','Acc_Y','Acc_Z','Mg_X','Mg_Y','Mg_Z','Ang_X','Ang_Y','Ang_Z','Fall_indicator']\n",
    "        data_for_fall_test.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAME TESTING SET\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "#Same process of split for testing data\n",
    "test_X_window = []\n",
    "test_Y_window = []\n",
    "for dataset in data_for_fall_test:\n",
    "    #Get the fall event location in the file (only one file at a time)\n",
    "    fall_event_loc = dataset[dataset['Fall_indicator']>0].index\n",
    "    data_index_lists = []\n",
    "    #Get 2 seconds of data around fall event\n",
    "    for fall_loc in fall_event_loc:\n",
    "        #2s of data - 1.5sec before fall, 0.5sec after fall\n",
    "        data_index_lists.append(list(range(fall_loc-40,fall_loc+20)))\n",
    "    #Get all the indices as a list    \n",
    "    drop_arr = list(chain.from_iterable(data_index_lists))\n",
    "    #Take only those indices that correspond to 2 seconds of data around fall event\n",
    "    dataset_sample = dataset.iloc[drop_arr]\n",
    "    \n",
    "\n",
    "    #Create windowed data for the file\n",
    "    test_each_X, test_each_Y = create_dataset(\n",
    "        dataset_sample[['Acc_X', 'Acc_Y', 'Acc_Z']],\n",
    "        dataset_sample[['Fall_indicator']],\n",
    "        feature_size=20\n",
    "    )\n",
    "    \n",
    "    #Adding only non-fall data from the files\n",
    "    data_index_lists_non_fall=[]\n",
    "    for fall_loc in fall_event_loc:\n",
    "        #2s of data - 10 seconds before fall, duration is 2 seconds\n",
    "        data_index_lists_non_fall.append(list(range(fall_loc-600,fall_loc-560)))\n",
    "    #Get all the indices as a list    \n",
    "    drop_arr = list(chain.from_iterable(data_index_lists_non_fall))\n",
    "    #Take only those indices that correspond to 2 seconds of data around fall event\n",
    "    dataset_sample_non_fall = dataset.iloc[drop_arr]\n",
    "    \n",
    "\n",
    "    #Create windowed data for the file\n",
    "    test_each_X_non_fall, test_each_Y_non_fall = create_dataset(\n",
    "        dataset_sample_non_fall[['Acc_X', 'Acc_Y', 'Acc_Z']],\n",
    "        dataset_sample_non_fall[['Fall_indicator']],\n",
    "        feature_size=20\n",
    "    )\n",
    "    \n",
    "    #Flatten the windowed data to get 60 features in a row\n",
    "    test_each_X_flat = np.stack([to_features(d) for d in test_each_X])\n",
    "    test_each_X_flat_non_fall = np.stack([to_features(d) for d in test_each_X_non_fall])\n",
    "    \n",
    "    #Append the data of each file\n",
    "    test_X_window.append(test_each_X_flat)\n",
    "    test_X_window.append(test_each_X_flat_non_fall)\n",
    "    \n",
    "    \n",
    "    test_Y_window.append(test_each_Y)\n",
    "    test_Y_window.append(test_each_Y_non_fall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.6197, -1.8438,  9.1056, -3.6197, -1.8438,  9.1056, -3.5911,\n",
       "       -1.9001,  9.0778, -3.5911, -1.9282,  9.0778, -3.5625, -1.9282,\n",
       "        9.0778, -3.5625, -1.9001,  9.1056, -3.5625, -1.9001,  9.1056,\n",
       "       -3.5625, -1.9001,  9.1334, -3.5339, -1.9001,  9.1334, -3.5339,\n",
       "       -1.9001,  9.1613, -3.5339, -1.9001,  9.1613, -3.5339, -1.9001,\n",
       "        9.1613, -3.5339, -1.9282,  9.1334, -3.4767, -1.9001,  9.1334,\n",
       "       -3.5053, -1.9282,  9.1334, -3.5053, -1.9282,  9.1334, -3.5053,\n",
       "       -1.9564,  9.1334, -3.4767, -1.9564,  9.1334, -3.4767, -1.9845,\n",
       "        9.1334, -3.448 , -1.9564,  9.1334])"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_window[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.1077 , -0.60521,  7.354  , ..., -4.7643 , -0.54891,  6.4087 ],\n",
       "       [-5.1077 , -0.57706,  7.6599 , ..., -4.564  , -0.49261,  6.3253 ],\n",
       "       [-4.8502 , -0.40816,  7.2428 , ..., -4.3923 , -0.35187,  6.1307 ],\n",
       "       ...,\n",
       "       [-0.7869 , -1.6186 ,  9.7173 , ..., -0.87274, -1.5904 ,  9.7173 ],\n",
       "       [-0.7869 , -1.6467 ,  9.6617 , ..., -0.87274, -1.6186 ,  9.7173 ],\n",
       "       [-0.75828, -1.6749 ,  9.6061 , ..., -0.87274, -1.6186 ,  9.6617 ]])"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = np.concatenate(test_X_window, axis = 0)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 60)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [3],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y = np.concatenate(test_Y_window, axis=0)\n",
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 1)"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all labels of fall_indicator > 1 to 1\n",
    "test_Y[test_Y > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argwhere(test_Y == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.argwhere(test_Y == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_labels = np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t83.88889%\n",
      "\n",
      "\n",
      "\n",
      "The Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       246\n",
      "           1       0.80      0.66      0.72       114\n",
      "\n",
      "    accuracy                           0.84       360\n",
      "   macro avg       0.83      0.79      0.80       360\n",
      "weighted avg       0.84      0.84      0.83       360\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Accuracy:\\t{:0.5f}%'.format(accuracy_score(test_Y,Y_pred_labels)*100))\n",
    "print(\"\\n\\n\")\n",
    "print(\"The Classification Report is\")\n",
    "print(classification_report(test_Y, Y_pred_labels))\n",
    "print(\"\\n\\n\")\n",
    "# print(\"The Confusion Matrix is\")\n",
    "matrix = confusion_matrix(test_Y, Y_pred_labels)\n",
    "plot1 = sns.heatmap(matrix,annot=True,cbar=False,fmt='d')  \n",
    "plt.ylabel('True Value')  \n",
    "plt.xlabel('Predicted Value')  \n",
    "plt.title('Basic Feed forward NN Confusion Matrix')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
